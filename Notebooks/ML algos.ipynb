{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms\n",
    "We will train and test our dataset on 5 differnt algorithms-\n",
    "\n",
    "1. Naive-Bayes Classifier\n",
    "2. Random Forest\n",
    "3. Linear SVM\n",
    "4. MLP Classifier\n",
    "5. Logistic REgression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the preprocessed data\n",
    "\n",
    "data=pd.read_csv('data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Post ID', 'Title', 'Url', 'Author',\n",
       "       'Score', 'Publish Date', 'Total No. of Comments', 'Permalink', 'Flair',\n",
       "       'Over 18', 'Selftext', 'Comments', 'Title+Selftext',\n",
       "       'Title_preprocessed_no_token'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics              8425\n",
       "Non-Political         6988\n",
       "Coronavirus           6228\n",
       "AskIndia              4328\n",
       "Policy/Economy        1270\n",
       "Science/Technology    1202\n",
       "Business/Finance      1080\n",
       "CAA-NRC               1070\n",
       "Name: Flair, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs=['Politics','Non-Political','Coronavirus','AskIndia','Policy/Economy','Science/Technology','Business/Finance','CAA-NRC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Selftext']=data['Selftext'].fillna(' ')\n",
    "data['Selftext'].replace({'[removed]':' ','[deleted]':''},inplace=True)\n",
    "data['Comments']=data['Comments'].fillna(' ')\n",
    "data['Comments'].replace({'[removed]':' ','[deleted]':''},inplace=True)\n",
    "data['Permalink']=data['Permalink'].fillna(' ')\n",
    "data['Permalink'].replace({'[removed]':' ','[deleted]':''},inplace=True)\n",
    "data['Title_preprocessed_no_token']=data['Title_preprocessed_no_token'].fillna(' ')\n",
    "data['Title_preprocessed_no_token'].replace({'[removed]':' ','[deleted]':''},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def nb_classifier(X_train, X_test, y_train, y_test):\n",
    "  \n",
    "  \n",
    "    nb = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', MultinomialNB()),\n",
    "                ])\n",
    "    nb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = nb.predict(X_test)\n",
    "\n",
    "    return accuracy_score(y_pred, y_test), classification_report(y_test, y_pred,target_names=flairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "def linear_svm(X_train, X_test, y_train, y_test):\n",
    "  \n",
    "  \n",
    "\n",
    "    sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "                 ])\n",
    "    sgd.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = sgd.predict(X_test)\n",
    "\n",
    "    return accuracy_score(y_pred, y_test),classification_report(y_test, y_pred,target_names=flairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regrassion\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def logisticreg(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', LogisticRegression(n_jobs=1, C=1e5,max_iter=500)),\n",
    "                 ])\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    return accuracy_score(y_pred, y_test),classification_report(y_test, y_pred,target_names=flairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def randomforest(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    ranfor = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', RandomForestClassifier(n_estimators = 1000, random_state = 42)),\n",
    "                 ])\n",
    "    ranfor.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = ranfor.predict(X_test)\n",
    "\n",
    "    return accuracy_score(y_pred, y_test),classification_report(y_test, y_pred,target_names=flairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP CLassifier\n",
    "\n",
    "def mlpclassifier(X_train, X_test, y_train, y_test):\n",
    "  \n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    \n",
    "    \n",
    "    mlp = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', MLPClassifier(hidden_layer_sizes=(30,30,30))),\n",
    "                 ])\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = mlp.predict(X_test)\n",
    "\n",
    "    return accuracy_score(y_pred, y_test),classification_report(y_test, y_pred,target_names=flairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make 4 combinations for our feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flair Detection using Title as Feature\n",
      "NB Classifier: \n",
      "accuracy:  0.5036770714168982\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.54      0.23      0.32       863\n",
      "     Non-Political       0.87      0.06      0.11       225\n",
      "       Coronavirus       0.00      0.00      0.00       219\n",
      "          AskIndia       0.57      0.69      0.62      1243\n",
      "    Policy/Economy       0.41      0.43      0.42      1406\n",
      "Science/Technology       0.86      0.02      0.05       245\n",
      "  Business/Finance       0.51      0.84      0.63      1656\n",
      "           CAA-NRC       0.82      0.03      0.07       262\n",
      "\n",
      "          accuracy                           0.50      6119\n",
      "         macro avg       0.57      0.29      0.28      6119\n",
      "      weighted avg       0.52      0.50      0.45      6119\n",
      "\n",
      "Linear SVM: \n",
      "accuracy:  0.5273737538813532\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.48      0.34      0.40       863\n",
      "     Non-Political       0.56      0.32      0.41       225\n",
      "       Coronavirus       0.17      0.01      0.02       219\n",
      "          AskIndia       0.56      0.76      0.64      1243\n",
      "    Policy/Economy       0.49      0.31      0.38      1406\n",
      "Science/Technology       0.51      0.20      0.29       245\n",
      "  Business/Finance       0.53      0.82      0.65      1656\n",
      "           CAA-NRC       0.55      0.27      0.36       262\n",
      "\n",
      "          accuracy                           0.53      6119\n",
      "         macro avg       0.48      0.38      0.39      6119\n",
      "      weighted avg       0.51      0.53      0.49      6119\n",
      "\n",
      "Logistic Reg: \n",
      "accuracy:  0.4613498937734924\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.37      0.35      0.36       863\n",
      "     Non-Political       0.39      0.38      0.39       225\n",
      "       Coronavirus       0.28      0.25      0.27       219\n",
      "          AskIndia       0.55      0.56      0.56      1243\n",
      "    Policy/Economy       0.39      0.40      0.40      1406\n",
      "Science/Technology       0.31      0.32      0.32       245\n",
      "  Business/Finance       0.57      0.58      0.57      1656\n",
      "           CAA-NRC       0.34      0.27      0.30       262\n",
      "\n",
      "          accuracy                           0.46      6119\n",
      "         macro avg       0.40      0.39      0.39      6119\n",
      "      weighted avg       0.46      0.46      0.46      6119\n",
      "\n",
      "Random Forest: \n",
      "accuracy:  0.5474750776270633\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.46      0.38      0.42       863\n",
      "     Non-Political       0.50      0.27      0.35       225\n",
      "       Coronavirus       0.42      0.11      0.17       219\n",
      "          AskIndia       0.62      0.72      0.67      1243\n",
      "    Policy/Economy       0.44      0.54      0.49      1406\n",
      "Science/Technology       0.58      0.27      0.37       245\n",
      "  Business/Finance       0.62      0.71      0.66      1656\n",
      "           CAA-NRC       0.49      0.16      0.24       262\n",
      "\n",
      "          accuracy                           0.55      6119\n",
      "         macro avg       0.52      0.39      0.42      6119\n",
      "      weighted avg       0.54      0.55      0.53      6119\n",
      "\n",
      "MLP Classifier: \n",
      "accuracy:  0.4544860271286158\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.32      0.38      0.35       863\n",
      "     Non-Political       0.33      0.32      0.32       225\n",
      "       Coronavirus       0.33      0.26      0.29       219\n",
      "          AskIndia       0.56      0.54      0.55      1243\n",
      "    Policy/Economy       0.39      0.37      0.38      1406\n",
      "Science/Technology       0.32      0.30      0.31       245\n",
      "  Business/Finance       0.57      0.61      0.59      1656\n",
      "           CAA-NRC       0.32      0.25      0.28       262\n",
      "\n",
      "          accuracy                           0.45      6119\n",
      "         macro avg       0.39      0.38      0.38      6119\n",
      "      weighted avg       0.45      0.45      0.45      6119\n",
      "\n",
      "------------------------------\n",
      "Flair Detection using Comments as Feature\n",
      "NB Classifier: \n",
      "accuracy:  0.3242359862722667\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.65      0.08      0.14       863\n",
      "     Non-Political       0.00      0.00      0.00       225\n",
      "       Coronavirus       0.00      0.00      0.00       219\n",
      "          AskIndia       0.61      0.20      0.30      1243\n",
      "    Policy/Economy       0.34      0.04      0.07      1406\n",
      "Science/Technology       0.00      0.00      0.00       245\n",
      "  Business/Finance       0.30      0.98      0.45      1656\n",
      "           CAA-NRC       0.00      0.00      0.00       262\n",
      "\n",
      "          accuracy                           0.32      6119\n",
      "         macro avg       0.24      0.16      0.12      6119\n",
      "      weighted avg       0.37      0.32      0.22      6119\n",
      "\n",
      "Linear SVM: \n",
      "accuracy:  0.37653211309037427\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.49      0.26      0.34       863\n",
      "     Non-Political       0.36      0.02      0.03       225\n",
      "       Coronavirus       0.25      0.00      0.01       219\n",
      "          AskIndia       0.51      0.32      0.40      1243\n",
      "    Policy/Economy       0.26      0.60      0.36      1406\n",
      "Science/Technology       0.39      0.06      0.11       245\n",
      "  Business/Finance       0.51      0.50      0.50      1656\n",
      "           CAA-NRC       0.29      0.01      0.01       262\n",
      "\n",
      "          accuracy                           0.38      6119\n",
      "         macro avg       0.38      0.22      0.22      6119\n",
      "      weighted avg       0.42      0.38      0.35      6119\n",
      "\n",
      "Logistic Reg: \n",
      "accuracy:  0.3384539957509397\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.37      0.21      0.27       863\n",
      "     Non-Political       0.12      0.02      0.04       225\n",
      "       Coronavirus       0.19      0.08      0.11       219\n",
      "          AskIndia       0.50      0.25      0.33      1243\n",
      "    Policy/Economy       0.26      0.69      0.38      1406\n",
      "Science/Technology       0.22      0.10      0.14       245\n",
      "  Business/Finance       0.54      0.34      0.42      1656\n",
      "           CAA-NRC       0.20      0.03      0.05       262\n",
      "\n",
      "          accuracy                           0.34      6119\n",
      "         macro avg       0.30      0.21      0.22      6119\n",
      "      weighted avg       0.39      0.34      0.32      6119\n",
      "\n",
      "Random Forest: \n",
      "accuracy:  0.3691779702565779\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.59      0.20      0.30       863\n",
      "     Non-Political       0.00      0.00      0.00       225\n",
      "       Coronavirus       0.00      0.00      0.00       219\n",
      "          AskIndia       0.53      0.29      0.38      1243\n",
      "    Policy/Economy       0.26      0.65      0.37      1406\n",
      "Science/Technology       0.50      0.00      0.01       245\n",
      "  Business/Finance       0.49      0.49      0.49      1656\n",
      "           CAA-NRC       0.00      0.00      0.00       262\n",
      "\n",
      "          accuracy                           0.37      6119\n",
      "         macro avg       0.30      0.20      0.19      6119\n",
      "      weighted avg       0.40      0.37      0.34      6119\n",
      "\n",
      "MLP Classifier: \n",
      "accuracy:  0.3312632783134499\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.37      0.19      0.25       863\n",
      "     Non-Political       0.18      0.04      0.06       225\n",
      "       Coronavirus       0.18      0.11      0.13       219\n",
      "          AskIndia       0.47      0.25      0.33      1243\n",
      "    Policy/Economy       0.26      0.68      0.38      1406\n",
      "Science/Technology       0.21      0.08      0.12       245\n",
      "  Business/Finance       0.55      0.33      0.41      1656\n",
      "           CAA-NRC       0.08      0.02      0.03       262\n",
      "\n",
      "          accuracy                           0.33      6119\n",
      "         macro avg       0.29      0.21      0.21      6119\n",
      "      weighted avg       0.38      0.33      0.31      6119\n",
      "\n",
      "------------------------------\n",
      "Flair Detection using Selftext and Title as Feature\n",
      "NB Classifier: \n",
      "accuracy:  0.5245955221441412\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.50      0.50      0.50       863\n",
      "     Non-Political       1.00      0.02      0.04       225\n",
      "       Coronavirus       0.00      0.00      0.00       219\n",
      "          AskIndia       0.61      0.67      0.64      1243\n",
      "    Policy/Economy       0.45      0.39      0.42      1406\n",
      "Science/Technology       1.00      0.01      0.02       245\n",
      "  Business/Finance       0.52      0.84      0.64      1656\n",
      "           CAA-NRC       0.75      0.01      0.02       262\n",
      "\n",
      "          accuracy                           0.52      6119\n",
      "         macro avg       0.60      0.31      0.29      6119\n",
      "      weighted avg       0.55      0.52      0.47      6119\n",
      "\n",
      "Linear SVM: \n",
      "accuracy:  0.5476385030233698\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.54      0.49      0.51       863\n",
      "     Non-Political       0.58      0.31      0.40       225\n",
      "       Coronavirus       0.29      0.01      0.02       219\n",
      "          AskIndia       0.57      0.77      0.65      1243\n",
      "    Policy/Economy       0.53      0.30      0.38      1406\n",
      "Science/Technology       0.58      0.21      0.31       245\n",
      "  Business/Finance       0.54      0.83      0.65      1656\n",
      "           CAA-NRC       0.59      0.21      0.31       262\n",
      "\n",
      "          accuracy                           0.55      6119\n",
      "         macro avg       0.53      0.39      0.41      6119\n",
      "      weighted avg       0.54      0.55      0.51      6119\n",
      "\n",
      "Logistic Reg: \n",
      "accuracy:  0.46314757313286486\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.40      0.41      0.40       863\n",
      "     Non-Political       0.39      0.35      0.37       225\n",
      "       Coronavirus       0.29      0.32      0.31       219\n",
      "          AskIndia       0.55      0.54      0.55      1243\n",
      "    Policy/Economy       0.41      0.40      0.40      1406\n",
      "Science/Technology       0.28      0.31      0.29       245\n",
      "  Business/Finance       0.56      0.57      0.57      1656\n",
      "           CAA-NRC       0.32      0.27      0.29       262\n",
      "\n",
      "          accuracy                           0.46      6119\n",
      "         macro avg       0.40      0.40      0.40      6119\n",
      "      weighted avg       0.46      0.46      0.46      6119\n",
      "\n",
      "Random Forest: \n",
      "accuracy:  0.5536852426867135\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.46      0.60      0.52       863\n",
      "     Non-Political       0.51      0.27      0.35       225\n",
      "       Coronavirus       0.42      0.10      0.16       219\n",
      "          AskIndia       0.65      0.68      0.66      1243\n",
      "    Policy/Economy       0.46      0.50      0.48      1406\n",
      "Science/Technology       0.61      0.25      0.35       245\n",
      "  Business/Finance       0.63      0.69      0.66      1656\n",
      "           CAA-NRC       0.52      0.19      0.28       262\n",
      "\n",
      "          accuracy                           0.55      6119\n",
      "         macro avg       0.53      0.41      0.43      6119\n",
      "      weighted avg       0.55      0.55      0.54      6119\n",
      "\n",
      "MLP Classifier: \n",
      "accuracy:  0.47017486517404805\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.36      0.47      0.40       863\n",
      "     Non-Political       0.34      0.38      0.36       225\n",
      "       Coronavirus       0.31      0.25      0.28       219\n",
      "          AskIndia       0.56      0.56      0.56      1243\n",
      "    Policy/Economy       0.44      0.35      0.39      1406\n",
      "Science/Technology       0.33      0.29      0.31       245\n",
      "  Business/Finance       0.58      0.61      0.59      1656\n",
      "           CAA-NRC       0.30      0.28      0.29       262\n",
      "\n",
      "          accuracy                           0.47      6119\n",
      "         macro avg       0.40      0.40      0.40      6119\n",
      "      weighted avg       0.47      0.47      0.47      6119\n",
      "\n",
      "------------------------------\n",
      "Flair Detection using Selftext, Title and Permalink as Feature\n",
      "NB Classifier: \n",
      "accuracy:  0.5190390586697172\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.51      0.47      0.49       863\n",
      "     Non-Political       1.00      0.01      0.03       225\n",
      "       Coronavirus       0.00      0.00      0.00       219\n",
      "          AskIndia       0.61      0.65      0.63      1243\n",
      "    Policy/Economy       0.45      0.39      0.42      1406\n",
      "Science/Technology       1.00      0.00      0.01       245\n",
      "  Business/Finance       0.51      0.86      0.64      1656\n",
      "           CAA-NRC       1.00      0.01      0.02       262\n",
      "\n",
      "          accuracy                           0.52      6119\n",
      "         macro avg       0.63      0.30      0.28      6119\n",
      "      weighted avg       0.56      0.52      0.47      6119\n",
      "\n",
      "Linear SVM: \n",
      "accuracy:  0.5489459061938226\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.54      0.50      0.52       863\n",
      "     Non-Political       0.59      0.30      0.40       225\n",
      "       Coronavirus       0.20      0.01      0.03       219\n",
      "          AskIndia       0.57      0.76      0.65      1243\n",
      "    Policy/Economy       0.53      0.30      0.38      1406\n",
      "Science/Technology       0.61      0.24      0.35       245\n",
      "  Business/Finance       0.54      0.82      0.66      1656\n",
      "           CAA-NRC       0.61      0.22      0.32       262\n",
      "\n",
      "          accuracy                           0.55      6119\n",
      "         macro avg       0.52      0.40      0.41      6119\n",
      "      weighted avg       0.54      0.55      0.51      6119\n",
      "\n",
      "Logistic Reg: \n",
      "accuracy:  0.49730348096094135\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.42      0.43      0.42       863\n",
      "     Non-Political       0.46      0.35      0.40       225\n",
      "       Coronavirus       0.34      0.24      0.28       219\n",
      "          AskIndia       0.59      0.59      0.59      1243\n",
      "    Policy/Economy       0.41      0.41      0.41      1406\n",
      "Science/Technology       0.40      0.31      0.35       245\n",
      "  Business/Finance       0.57      0.65      0.61      1656\n",
      "           CAA-NRC       0.40      0.28      0.33       262\n",
      "\n",
      "          accuracy                           0.50      6119\n",
      "         macro avg       0.45      0.41      0.42      6119\n",
      "      weighted avg       0.49      0.50      0.49      6119\n",
      "\n",
      "Random Forest: \n",
      "accuracy:  0.5463310998529172\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.46      0.59      0.52       863\n",
      "     Non-Political       0.49      0.27      0.34       225\n",
      "       Coronavirus       0.39      0.08      0.13       219\n",
      "          AskIndia       0.65      0.66      0.65      1243\n",
      "    Policy/Economy       0.48      0.43      0.46      1406\n",
      "Science/Technology       0.67      0.24      0.35       245\n",
      "  Business/Finance       0.57      0.74      0.64      1656\n",
      "           CAA-NRC       0.58      0.20      0.30       262\n",
      "\n",
      "          accuracy                           0.55      6119\n",
      "         macro avg       0.54      0.40      0.42      6119\n",
      "      weighted avg       0.54      0.55      0.53      6119\n",
      "\n",
      "MLP Classifier: \n",
      "accuracy:  0.4616767445661056\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Politics       0.35      0.45      0.40       863\n",
      "     Non-Political       0.33      0.25      0.28       225\n",
      "       Coronavirus       0.30      0.20      0.24       219\n",
      "          AskIndia       0.55      0.55      0.55      1243\n",
      "    Policy/Economy       0.41      0.43      0.42      1406\n",
      "Science/Technology       0.35      0.24      0.29       245\n",
      "  Business/Finance       0.61      0.57      0.59      1656\n",
      "           CAA-NRC       0.21      0.24      0.22       262\n",
      "\n",
      "          accuracy                           0.46      6119\n",
      "         macro avg       0.39      0.36      0.37      6119\n",
      "      weighted avg       0.47      0.46      0.46      6119\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "A = data['Title_preprocessed_no_token']   \n",
    "B = data['Comments']\n",
    "C = data['Selftext']+A\n",
    "D = data['Selftext']+data['Title_preprocessed_no_token']+data['Permalink']\n",
    "\n",
    "y=data['Flair']\n",
    "\n",
    "\n",
    "# Callings methods for 1st feature.\n",
    "print(\"Flair Detection using Title as Feature\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(A, y, test_size=0.2, random_state = 42) \n",
    "\n",
    "print(\"NB Classifier: \")\n",
    "acc,report=nb_classifier(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"Linear SVM: \")\n",
    "acc,report=linear_svm(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"Logistic Reg: \")\n",
    "acc,report=logisticreg(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"Random Forest: \")\n",
    "acc,report=randomforest(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"MLP Classifier: \")\n",
    "acc,report=mlpclassifier(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "print('-'*30)\n",
    "\n",
    "\n",
    "# Callings methods for 2nd feature.\n",
    "print(\"Flair Detection using Comments as Feature\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(B, y, test_size=0.2, random_state = 42)\n",
    "print(\"NB Classifier: \")\n",
    "acc,report=nb_classifier(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"Linear SVM: \")\n",
    "acc,report=linear_svm(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"Logistic Reg: \")\n",
    "acc,report=logisticreg(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"Random Forest: \")\n",
    "acc,report=randomforest(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"MLP Classifier: \")\n",
    "acc,report=mlpclassifier(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "print('-'*30)\n",
    "\n",
    "\n",
    "# Callings methods for 3rd feature.\n",
    "print(\"Flair Detection using Selftext and Title as Feature\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(C, y, test_size=0.2, random_state = 42)\n",
    "print(\"NB Classifier: \")\n",
    "acc,report=nb_classifier(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"Linear SVM: \")\n",
    "acc,report=linear_svm(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"Logistic Reg: \")\n",
    "acc,report=logisticreg(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"Random Forest: \")\n",
    "acc,report=randomforest(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"MLP Classifier: \")\n",
    "acc,report=mlpclassifier(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "print('-'*30)\n",
    "\n",
    "\n",
    "\n",
    "# Callings methods for 4th feature.\n",
    "print(\"Flair Detection using Selftext, Title and Permalink as Feature\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(D, y, test_size=0.2, random_state = 42)\n",
    "print(\"NB Classifier: \")\n",
    "acc,report=nb_classifier(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"Linear SVM: \")\n",
    "acc,report=linear_svm(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"Logistic Reg: \")\n",
    "acc,report=logisticreg(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"Random Forest: \")\n",
    "acc,report=randomforest(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "\n",
    "print(\"MLP Classifier: \")\n",
    "acc,report=mlpclassifier(X_train, X_test, y_train, y_test)\n",
    "print('accuracy: ',acc)\n",
    "print(report)\n",
    "print('-'*30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models on the basis of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting graph \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "n=4\n",
    "index=np.arange(n)\n",
    "fig,ax = plt.subplots()\n",
    "data=[[50.367707,32.423598,52.459552,51.903905], #accuracies of NB\n",
    "      [52.733737,37.653211,54.763850,54.894590], #accuracies of SVM\n",
    "      [46.134989,33.845399,46.314757,49.730348], #accuracies of Logistic Regression\n",
    "      [54.747507,36.917797,55.368524,54.633109], #accuracies of Random Forest\n",
    "      [45.448602,33.126327,47.017486,46.690635]] #accuracies of MLP Classifer\n",
    "\n",
    "bar_width=0.1\n",
    "opacity=0.8\n",
    "\n",
    "rec1=plt.bar(index,data[0],bar_width,alpha=opacity,color='blue',label='NB')\n",
    "rec2=plt.bar(index+bar_width,data[1],bar_width,alpha=opacity,color='green',label='SVM')\n",
    "rec3=plt.bar(index+bar_width+bar_width,data[2],bar_width,alpha=opacity,color='red',label='LR')\n",
    "rec4=plt.bar(index+bar_width+bar_width+bar_width,data[3],bar_width,alpha=opacity,color='orange',label='RF')\n",
    "rec4=plt.bar(index+bar_width+bar_width+bar_width+bar_width,data[4],bar_width,alpha=opacity,color='brown',label='MLP')\n",
    "\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(index+bar_width+bar_width,('Title','Comments','Title+Selftext','Title+Selftext+Permalink'))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that feature (__Title+Selftext__) gives the best accuracy __55.36__ when trained on __Random Forest__ algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "\n",
    "import joblib\n",
    "filename = 'model.sav'\n",
    "joblib.dump(sgd,filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
